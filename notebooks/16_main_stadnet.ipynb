{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6acc93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to sys.path: c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to Python path to find the 'src' directory\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added project root to sys.path: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97051770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.ipynb content to be used in Jupyter Notebook format\n",
    "\n",
    "# Section 1: Setup\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from src.stadnet.stacked_model import STADNet\n",
    "from src.stadnet.pe_utils import add_temporal_pe, add_spatial_pe\n",
    "from src.stadnet.masked_loss import masked_mse\n",
    "from src.stadnet.evaluate import evaluate_model\n",
    "from src.stadnet.save_predictions import save_predictions_to_csv\n",
    "from src.stadnet.visualize_utils import plot_comparison\n",
    "from src.grid_utils import create_gridded_data\n",
    "from src.data_utils import split_data_chronologically\n",
    "# Section 4: Dataset Class from Grid\n",
    "from torch.utils.data import Dataset\n",
    "class GriddedSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, gridded_tensor, input_steps=12, target_steps=1, target_indices=[0, 1]):\n",
    "        self.data = torch.tensor(gridded_tensor, dtype=torch.float32)\n",
    "        self.input_steps = input_steps\n",
    "        self.target_steps = target_steps\n",
    "        self.target_indices = target_indices\n",
    "        self.grid_shape = self.data.shape[1:3]  # (H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.input_steps - self.target_steps + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx:idx + self.input_steps]  # [T, H, W, C]\n",
    "        X = X.permute(0, 3, 1, 2).float()           # → [T, C, H, W]\n",
    "        Y = self.data[idx + self.input_steps]      # [H, W, C]\n",
    "        Y = Y[..., self.target_indices].permute(2, 0, 1)  # [C_target, H, W]\n",
    "        return X, Y\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22ac0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\peera\\\\Desktop\\\\DroughtLSTM_oneday\\\\notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887095e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import optuna\n",
    "import os\n",
    "from src.stadnet.train import train_stadnet_model\n",
    "from src.stadnet.stacked_model import STADNet\n",
    "from src.stadnet.evaluate import evaluate_model\n",
    "from src.stadnet.save_predictions import save_predictions_to_csv\n",
    "from pathlib import Path\n",
    "from src.data_utils import split_data_chronologically\n",
    "from src.grid_utils import create_gridded_data\n",
    "class GriddedSeq2SeqDataset(Dataset):\n",
    "    def __init__(self, gridded_tensor, input_steps=12, target_steps=1, target_indices=[0, 1]):\n",
    "        self.data = torch.tensor(gridded_tensor, dtype=torch.float32)\n",
    "        self.input_steps = input_steps\n",
    "        self.target_steps = target_steps\n",
    "        self.target_indices = target_indices\n",
    "        self.grid_shape = self.data.shape[1:3]  # (H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.input_steps - self.target_steps + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx:idx + self.input_steps]  # [T, H, W, C]\n",
    "        X = X.permute(0, 3, 1, 2).float()           # → [T, C, H, W]\n",
    "        Y = self.data[idx + self.input_steps]      # [H, W, C]\n",
    "        Y = Y[..., self.target_indices].permute(2, 0, 1)  # [C_target, H, W]\n",
    "        return X, Y\n",
    "\n",
    "class STADNetForecastingPipeline:\n",
    "    def __init__(self, config_path):\n",
    "        self.config = yaml.safe_load(open(config_path))\n",
    "        self.model = None\n",
    "        self.land_mask = None\n",
    "        self.raw_df = None\n",
    "        self.study = None\n",
    "        self.best_params = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.full_df = pd.read_csv(self.config[\"data\"][\"csv_path\"])\n",
    "        self.raw_df = self.full_df  # For saving predictions\n",
    "\n",
    "        self.train_df, self.val_df, self.test_df = split_data_chronologically(self.full_df, self.config)\n",
    "        self.gridded_tensor_train, self.land_mask = create_gridded_data(self.train_df, self.config)  # assume same shape for all\n",
    "        self.gridded_tensor_val, self.land_mask = create_gridded_data(self.val_df, self.config)  # assume same shape for all\n",
    "        self.gridded_tensor_test, self.land_mask = create_gridded_data(self.test_df, self.config)  # assume same shape for all\n",
    "        self.gridded_tensor_full, self.land_mask = create_gridded_data(self.full_df, self.config)  # assume same shape for all\n",
    "        self.train_dataset = GriddedSeq2SeqDataset(\n",
    "            self.gridded_tensor_train,\n",
    "            input_steps=self.config['training']['input_steps'],\n",
    "            target_steps=self.config[\"training\"][\"output_steps\"],\n",
    "            target_indices=list(range(len(self.config[\"model\"][\"output_targets\"])))\n",
    "        )\n",
    "        self.val_dataset = GriddedSeq2SeqDataset(\n",
    "            self.gridded_tensor_val,\n",
    "            input_steps=self.config['training']['input_steps'],\n",
    "            target_steps=self.config[\"training\"][\"output_steps\"],\n",
    "            target_indices=list(range(len(self.config[\"model\"][\"output_targets\"])))\n",
    "        )\n",
    "        self.test_dataset = GriddedSeq2SeqDataset(\n",
    "            self.gridded_tensor_test,\n",
    "            input_steps=self.config['training']['input_steps'],\n",
    "            target_steps=self.config[\"training\"][\"output_steps\"],\n",
    "            target_indices=list(range(len(self.config[\"model\"][\"output_targets\"])))\n",
    "        )\n",
    "        self.full_dataset = GriddedSeq2SeqDataset(\n",
    "            self.gridded_tensor_full,\n",
    "            input_steps=self.config['training']['input_steps'],\n",
    "            target_steps=self.config[\"training\"][\"output_steps\"],\n",
    "            target_indices=list(range(len(self.config[\"model\"][\"output_targets\"])))\n",
    "        )\n",
    "        self.land_mask =  torch.tensor(self.land_mask, dtype=torch.float32).cuda()\n",
    "        Path(self.config[\"output\"][\"predictions_csv\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = STADNet(\n",
    "            input_channels=self.config[\"model\"][\"input_channels\"],\n",
    "            hidden_channels=self.config[\"model\"][\"hidden_channels\"],\n",
    "            n_layers=self.config[\"model\"][\"n_layers\"],\n",
    "            output_targets=self.config[\"model\"][\"output_targets\"]\n",
    "        ).cuda()\n",
    "\n",
    "    def train(self):\n",
    "        self.study = optuna.create_study(direction=\"minimize\")\n",
    "        self.study.optimize(lambda trial: self.objective(trial, self.config, self.train_dataset, self.val_dataset, self.land_mask), n_trials=10)\n",
    "\n",
    "        self.best_params = self.study.best_trial.params\n",
    "        print(\"Best hyperparameters found by Optuna:\", self.best_params)\n",
    "\n",
    "        # Reconstruct hidden_channels\n",
    "        n_layers = self.best_params['n_layers']\n",
    "        hidden_channels = [self.best_params[f'hidden_channels_{i}'] for i in range(n_layers)]\n",
    "        print(\"Reconstructed hidden_channels:\", hidden_channels)\n",
    "\n",
    "        cfg_final = self.config.copy()\n",
    "        cfg_final['model']['hidden_channels'] = hidden_channels\n",
    "        cfg_final['model']['n_layers'] = n_layers\n",
    "        cfg_final['training']['learning_rate'] = self.best_params['learning_rate']\n",
    "        cfg_final['training']['dropout_rate'] = self.best_params['dropout_rate']\n",
    "        cfg_final['training']['batch_size'] = self.best_params['batch_size']\n",
    "\n",
    "        self.train_val_dataset = ConcatDataset([self.train_dataset, self.val_dataset])\n",
    "        train_val_loader = DataLoader(self.train_val_dataset, batch_size=cfg_final['training']['batch_size'], shuffle=True)\n",
    "        test_loader = DataLoader(self.test_dataset, batch_size=cfg_final['training']['batch_size'], shuffle=False)\n",
    "\n",
    "        self.model = train_stadnet_model(train_val_loader, cfg_final, \n",
    "        val_loader=test_loader, land_mask=self.land_mask,log_path=self.config[\"output\"][\"predictions_csv\"]+\"prediction_log.csv\")\n",
    "        torch.save(self.model.state_dict(), \"final_model.pth\")\n",
    "\n",
    "        # Final evaluation\n",
    "        metrics = evaluate_model(self.model, test_loader, self.land_mask, output_targets=cfg_final['model']['output_targets'])\n",
    "        print(\"Final Evaluation on Test Set:\")\n",
    "        for target, vals in metrics.items():\n",
    "            print(f\"  {target}: {vals}\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        val_loader = DataLoader(self.val_dataset, batch_size=self.config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "        metrics = evaluate_model(self.model, val_loader, self.land_mask, self.config[\"model\"][\"output_targets\"])\n",
    "        print(\"Evaluation Metrics on Validation Set:\")\n",
    "        for target, vals in metrics.items():\n",
    "            print(f\"  {target}: {vals}\")\n",
    "        return metrics\n",
    "\n",
    "    def predict_and_save(self):\n",
    "        val_loader = DataLoader(self.val_dataset, batch_size=self.config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "        save_predictions_to_csv(\n",
    "            self.model,\n",
    "            val_loader,\n",
    "            self.land_mask,\n",
    "            self.config[\"model\"][\"output_targets\"],\n",
    "            self.raw_df,\n",
    "            self.config[\"output\"][\"predictions_csv\"]\n",
    "        )\n",
    "\n",
    "    def objective(self, trial, config, train_dataset, val_dataset, land_mask):\n",
    "\n",
    "        n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "        base_channels = trial.suggest_categorical('hidden_channels', [128, 256, 512])\n",
    "        hidden_channels = [base_channels] * n_layers\n",
    "        learning_rate = trial.suggest_float('learning_rate', 2e-5, 5e-3, log=True)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
    "        batch_size = trial.suggest_int('batch_size', 8, 32, step=8)\n",
    "\n",
    "        config['model']['hidden_channels'] = hidden_channels\n",
    "        config['model']['n_layers'] = n_layers\n",
    "        config['training']['learning_rate'] = learning_rate\n",
    "        config['training']['dropout_rate'] = dropout_rate\n",
    "        config['training']['batch_size'] = batch_size\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = train_stadnet_model(train_loader, config, val_loader=val_loader, land_mask=land_mask)\n",
    "        metrics = evaluate_model(model, val_loader, land_mask, output_targets=config['model']['output_targets'])\n",
    "        ret_error = []\n",
    "        for k,v in metrics.items():\n",
    "            ret_error.append(v['RMSE'])\n",
    "        return sum(ret_error) / len(ret_error)\n",
    "\n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.train()\n",
    "        self.evaluate()\n",
    "        self.predict_and_save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0adc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data: Train ends 2017-12-31 00:00:00, Validation ends 2020-12-31 00:00:00\n",
      "Warning: Time column 'time' is not datetime. Attempting conversion.\n",
      "Train set shape: (251316, 19), Time range: 1901-01-16 00:00:00 to 2017-12-16 00:00:00\n",
      "Validation set shape: (6444, 19), Time range: 2018-01-16 00:00:00 to 2020-12-16 00:00:00\n",
      "Test set shape: (6444, 19), Time range: 2021-01-16 00:00:00 to 2023-12-16 00:00:00\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (1404, 29, 16, 15)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\grid_utils.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['row_idx'] = ((df[lat_col] - lat_min) / fixed_step).round().astype(int)\n",
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\grid_utils.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['col_idx'] = ((df[lon_col] - lon_min) / fixed_step).round().astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (36, 29, 16, 15)...\n",
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (36, 29, 16, 15)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\grid_utils.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['row_idx'] = ((df[lat_col] - lat_min) / fixed_step).round().astype(int)\n",
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\grid_utils.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['col_idx'] = ((df[lon_col] - lon_min) / fixed_step).round().astype(int)\n",
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\grid_utils.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['row_idx'] = ((df[lat_col] - lat_min) / fixed_step).round().astype(int)\n",
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\grid_utils.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['col_idx'] = ((df[lon_col] - lon_min) / fixed_step).round().astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (1476, 29, 16, 15)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:41:34,316] A new study created in memory with name: no-name-9d3d26f7-73d2-4f29-865e-ae5112313e5d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Gridding Process Finished ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-19 03:41:35,218] Trial 0 failed with parameters: {'n_layers': 2, 'hidden_channels': 512, 'learning_rate': 0.0004171692439304797, 'dropout_rate': 0.23462311778297668, 'batch_size': 32} because of the following error: RuntimeError(\"shape '[32, -1, 1, 1]' is invalid for input of size 8\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\peera\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peera\\AppData\\Local\\Temp\\ipykernel_47324\\343227285.py\", line 87, in <lambda>\n",
      "    self.study.optimize(lambda trial: self.objective(trial, self.config, self.train_dataset, self.val_dataset, self.land_mask), n_trials=10)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peera\\AppData\\Local\\Temp\\ipykernel_47324\\343227285.py\", line 155, in objective\n",
      "    model = train_stadnet_model(train_loader, config, val_loader=val_loader, land_mask=land_mask)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\stadnet\\train.py\", line 48, in train_stadnet_model\n",
      "    y_pred = model(x_seq)  # [B, C, H, W]\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\stadnet\\stacked_model.py\", line 80, in forward\n",
      "    h[l], c_s[l], c_trend[l], c_event[l] = cell(x_t, h[l], c_s[l], c_trend[l], c_event[l], t, c_top_diag=diag_input)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\stadnet\\cell.py\", line 125, in forward\n",
      "    t_embed = t_embed.view(B, -1, 1, 1).expand(-1, -1, H, W)  # [B, 8, H, W]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: shape '[32, -1, 1, 1]' is invalid for input of size 8\n",
      "[W 2025-06-19 03:41:35,227] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, -1, 1, 1]' is invalid for input of size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m  STADNetForecastingPipeline(config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../config/stadnet/config_stadnet_pet.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 164\u001b[0m, in \u001b[0;36mSTADNetForecastingPipeline.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_and_save()\n",
      "Cell \u001b[1;32mIn[7], line 87\u001b[0m, in \u001b[0;36mSTADNetForecastingPipeline.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mland_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found by Optuna:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[7], line 87\u001b[0m, in \u001b[0;36mSTADNetForecastingPipeline.train.<locals>.<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mland_mask\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found by Optuna:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "Cell \u001b[1;32mIn[7], line 155\u001b[0m, in \u001b[0;36mSTADNetForecastingPipeline.objective\u001b[1;34m(self, trial, config, train_dataset, val_dataset, land_mask)\u001b[0m\n\u001b[0;32m    152\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    153\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 155\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_stadnet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mland_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_loader, land_mask, output_targets\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_targets\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    157\u001b[0m ret_error \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\stadnet\\train.py:48\u001b[0m, in \u001b[0;36mtrain_stadnet_model\u001b[1;34m(dataset, config, val_loader, land_mask, log_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m x_seq \u001b[38;5;241m=\u001b[39m add_spatial_pe(x_seq)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Forward pass to get model predictions\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_seq\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, C, H, W]\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Compute the total loss across all targets\u001b[39;00m\n\u001b[0;32m     51\u001b[0m output_targets \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_targets\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\stadnet\\stacked_model.py:80\u001b[0m, in \u001b[0;36mSTADNet.forward\u001b[1;34m(self, x_seq)\u001b[0m\n\u001b[0;32m     77\u001b[0m             x_t \u001b[38;5;241m=\u001b[39m x_t \u001b[38;5;241m+\u001b[39m h[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         diag_input \u001b[38;5;241m=\u001b[39m prev_top_c_event \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m prev_top_c_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m         h[l], c_s[l], c_trend[l], c_event[l] \u001b[38;5;241m=\u001b[39m \u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_s\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_trend\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_event\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_top_diag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_head(h[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Final output\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\stadnet\\cell.py:125\u001b[0m, in \u001b[0;36mSTADCell.forward\u001b[1;34m(self, x_t, h_prev, c_s_prev, c_trend_prev, c_event_prev, timestep, c_top_diag)\u001b[0m\n\u001b[0;32m    123\u001b[0m     timestep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([timestep], device\u001b[38;5;241m=\u001b[39mx_t\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    124\u001b[0m t_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embed(timestep \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embed\u001b[38;5;241m.\u001b[39mnum_embeddings)  \u001b[38;5;66;03m# [B, 8]\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m t_embed \u001b[38;5;241m=\u001b[39m \u001b[43mt_embed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, W)  \u001b[38;5;66;03m# [B, 8, H, W]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Fusion gate for h_trend and h_event\u001b[39;00m\n\u001b[0;32m    128\u001b[0m alpha_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([c_trend, c_event, t_embed], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[32, -1, 1, 1]' is invalid for input of size 8"
     ]
    }
   ],
   "source": [
    "pipeline =  STADNetForecastingPipeline(config_path='../config/stadnet/config_stadnet_pet.yaml')\n",
    "pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought_lstm_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
