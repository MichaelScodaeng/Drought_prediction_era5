{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a640f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to sys.path: c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\n",
      "Warning: Could not import from data_utils_v1 for __main__ block. Ensure it's accessible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.1 is exactly one major version older than the runtime version 6.31.1 at api.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to Python path to find the 'src' directory\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added project root to sys.path: {project_root}\")\n",
    "\n",
    "# Import your new ConvLSTM pipeline class\n",
    "from src.cnn3dpipeline import CNN3DPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c060429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from ../config/cnn3d/config_CNN3D_test.yaml\n",
      "Successfully loaded data from c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\data\\full.csv. Shape: (264204, 19)\n",
      "Converted column 'time' to datetime.\n",
      "Data sorted by ['time', 'lat', 'lon'].\n",
      "Splitting data: Train ends 2017-12-31 00:00:00, Validation ends 2020-12-31 00:00:00\n",
      "Train set shape: (251316, 19), Time range: 1901-01-16 00:00:00 to 2017-12-16 00:00:00\n",
      "Validation set shape: (6444, 19), Time range: 2018-01-16 00:00:00 to 2020-12-16 00:00:00\n",
      "Test set shape: (6444, 19), Time range: 2021-01-16 00:00:00 to 2023-12-16 00:00:00\n",
      "Columns to be scaled using robust scaler: ['pre', 'tmp', 'dtr', 'cld', 'tmx', 'tmn', 'wet', 'vap', 'soi', 'dmi', 'pdo', 'nino4', 'nino34', 'nino3', 'pet', 'pre']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\data_utils.py:59: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[time_col] = pd.to_datetime(df[time_col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaling complete.\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (1404, 29, 16, 15)...\n",
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (36, 29, 16, 15)...\n",
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (36, 29, 16, 15)...\n",
      "--- Data Gridding Process Finished ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 00:20:35,057] A new study created in memory with name: no-name-d2bbc0eb-b076-42eb-beac-a74955aa3a6c\n",
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\cnn3dpipeline.py:368: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2025-06-14 00:20:42,575] Trial 0 finished with value: 0.165983647108078 and parameters: {'batch_size': 8, 'n_conv_layers': 1, 'hidden_channels': 32, 'kernel_size': 1, 'dropout': 0.46404295089591946, 'use_batchnorm': True, 'learning_rate': 0.0018485626860917303}. Best is trial 0 with value: 0.165983647108078.\n",
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\cnn3dpipeline.py:368: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2025-06-14 00:20:43,432] Trial 1 finished with value: 0.15676699578762054 and parameters: {'batch_size': 16, 'n_conv_layers': 1, 'hidden_channels': 16, 'kernel_size': 1, 'dropout': 0.4334582819940417, 'use_batchnorm': True, 'learning_rate': 0.003980700214341597}. Best is trial 1 with value: 0.15676699578762054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'batch_size': 16, 'n_conv_layers': 1, 'hidden_channels': 16, 'kernel_size': 1, 'dropout': 0.4334582819940417, 'use_batchnorm': True, 'learning_rate': 0.003980700214341597}\n",
      "[Final Training] Epoch 1/2 - Val Loss: 0.1591\n",
      "✅ Best final model saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn3d\\..\\..\\models_saved\\CNN3D_test_Run\\cnn3d_final_model.pt\n",
      "[Final Training] Epoch 2/2 - Val Loss: 0.1477\n",
      "✅ Best final model saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn3d\\..\\..\\models_saved\\CNN3D_test_Run\\cnn3d_final_model.pt\n",
      "Final model training completed.\n",
      "Final model saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn3d\\..\\..\\models_saved\\CNN3D_test_Run\\cnn3d_final_model.pt\n",
      "Evaluating on train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - RMSE: 44.1273, MAE: 21.0885, R2: 0.7356\n",
      "Evaluating on val set...\n",
      "Val Set - RMSE: 43.7501, MAE: 23.0924, R2: 0.7211\n",
      "Evaluating on test set...\n",
      "Test Set - RMSE: 50.5585, MAE: 27.2080, R2: 0.6236\n",
      "Metrics saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn3d\\..\\..\\run_outputs\\CNN3D_test_Run\\evaluation_metrics.json\n",
      "Successfully loaded data from c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\data\\full.csv. Shape: (264204, 19)\n",
      "Converted column 'time' to datetime.\n",
      "Data sorted by ['time', 'lat', 'lon'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\data_utils.py:59: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[time_col] = pd.to_datetime(df[time_col])\n",
      "Saving predictions: 100%|██████████| 1440/1440 [00:55<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Full predictions saved to: c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn3d\\..\\..\\run_outputs\\CNN3D_test_Run\\full_data_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_pipeline(config_path):\n",
    "    \"\"\"\n",
    "    Run the CNN3D pipeline with the specified configuration file.\n",
    "    \n",
    "    Args:\n",
    "        config_path (str): Path to the configuration YAML file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results of the pipeline run, including model performance metrics.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n",
    "    \n",
    "    # Load the configuration\n",
    "    print(f\"Loading configuration from: {config_path}\")\n",
    "    \n",
    "    # Create an instance of the CNN3DPipeline\n",
    "    pipeline = CNN3DPipeline(config_path=config_path)\n",
    "    \n",
    "    # Run the pipeline\n",
    "    # 1. Train the model using fixed config (with early stopping)\n",
    "    pipeline.tune_and_train()\n",
    "\n",
    "    # 2. Evaluate on train/val/test\n",
    "    metrics = pipeline.evaluate()\n",
    "\n",
    "    # 3. Predict on full data (train + val + test) and save to CSV\n",
    "    full_df = pipeline.predict_on_full_data()\n",
    "    \n",
    "    return pipeline, full_df, metrics\n",
    "\n",
    "config_file_test = \"../config/cnn3d/config_CNN3D_test.yaml\" \n",
    "# Create an instance of the CNN3DPipeline\n",
    "pipeline = CNN3DPipeline(config_path=config_file_test)\n",
    "\n",
    "# Run the pipeline\n",
    "# 1. Train the model using fixed config (with early stopping)\n",
    "pipeline.tune_and_train()\n",
    "\n",
    "# 2. Evaluate on train/val/test\n",
    "metrics = pipeline.evaluate()\n",
    "\n",
    "# 3. Predict on full data (train + val + test) and save to CSV\n",
    "full_df = pipeline.predict_on_full_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_file_test = \"../config/cnn3d/config_CNN3D_SPEI.yaml\" \n",
    "    pipeline, full_df, metrics = run_pipeline(config_file_test)\n",
    "    print(\"\\n--- Pipeline Execution Finished ---\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Full Data Predictions Shape: {full_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931525bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_file_test = \"../config/cnn3d/config_CNN3D_PRE.yaml\" \n",
    "    pipeline, full_df, metrics = run_pipeline(config_file_test)\n",
    "    print(\"\\n--- Pipeline Execution Finished ---\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Full Data Predictions Shape: {full_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_file_test = \"../config/cnn3d/config_CNN3D_PET.yaml\" \n",
    "    pipeline, full_df, metrics = run_pipeline(config_file_test)\n",
    "    print(\"\\n--- Pipeline Execution Finished ---\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Full Data Predictions Shape: {full_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline execution failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought_lstm_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
