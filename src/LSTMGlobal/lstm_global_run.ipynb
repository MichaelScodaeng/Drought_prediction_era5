{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e94689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to sys.path: c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday_era5\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added project root to sys.path: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e637f923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.1 is exactly one major version older than the runtime version 6.31.1 at api.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] Initialized with 111 samples.\n",
      "[Dataset] Estimated size: 10979.29 MB\n"
     ]
    }
   ],
   "source": [
    "from src.XGBoostGlobal.XGBoostGlobal import XGBoostGridMultiStepPipeline\n",
    "from src.GriddedClimateDataset import GriddedClimateDataset\n",
    "INPUT_LEN = 12  # Number of input time steps\n",
    "FORECAST_LEN = 6  # Number of forecast time steps\n",
    "PATH = \"gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr\"\n",
    "VARIABLES = [\n",
    "    'total_precipitation_6hr',\n",
    "    '2m_temperature', '2m_dewpoint_temperature', 'surface_pressure',\n",
    "    'mean_sea_level_pressure', '10m_u_component_of_wind', '10m_v_component_of_wind',\n",
    "    '10m_wind_speed', 'u_component_of_wind', 'v_component_of_wind',\n",
    "    'total_column_water_vapour', 'integrated_vapor_transport', 'boundary_layer_height',\n",
    "    'specific_humidity', 'total_cloud_cover',\n",
    "    'mean_surface_net_short_wave_radiation_flux',\n",
    "    'mean_surface_latent_heat_flux', 'mean_surface_sensible_heat_flux',\n",
    "    'snow_depth', 'sea_surface_temperature', 'volumetric_soil_water_layer_1',\n",
    "    'mean_vertically_integrated_moisture_divergence', 'eddy_kinetic_energy',\n",
    "    'land_sea_mask'\n",
    "]\n",
    "TARGET_VARIABLE = 'total_precipitation_6hr'\n",
    "dataset = GriddedClimateDataset(PATH, input_len=INPUT_LEN, forecast_len=FORECAST_LEN, \n",
    "                                  variables=VARIABLES, target_variable=TARGET_VARIABLE,time_slice=slice(\"2022-01-01\", \"2022-02-01\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b77e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\peera\\\\Desktop\\\\DroughtLSTM_oneday_era5\\\\src\\\\LSTMGlobal'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca0c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Memory-Efficient LSTM Global Pipeline with WeatherBench2 ---\n",
      "[Pipeline Start] GPU Memory - Allocated: 0.00GB, Cached: 0.00GB\n",
      "[Pipeline Start] CPU Memory Used: 14.24GB\n",
      "[Dataset] Initialized with 343 samples.\n",
      "[Dataset] Estimated size: 30870.41 MB\n",
      "No scaler loaded; assuming data is already normalized.\n",
      "Dataset splits - Train: 248, Val: 27, Test: 68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLSTMGlobal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlstm_global\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTMPyTorchGlobalPipeline\n\u001b[0;32m      2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m LSTMPyTorchGlobalPipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./config_lstmglobal.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday_era5\\src\\LSTMGlobal\\lstm_global.py:392\u001b[0m, in \u001b[0;36mLSTMPyTorchGlobalPipeline.run_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[0;32m    389\u001b[0m                         num_workers\u001b[38;5;241m=\u001b[39mnum_workers, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# Determine model input size\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m sample_x, sample_y \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    393\u001b[0m C, T, H, W \u001b[38;5;241m=\u001b[39m sample_x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    394\u001b[0m input_size \u001b[38;5;241m=\u001b[39m C \u001b[38;5;241m*\u001b[39m H \u001b[38;5;241m*\u001b[39m W\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday_era5\\src\\LSTMGlobal\\lstm_global.py:171\u001b[0m, in \u001b[0;36mLargeScaledGriddedClimateDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m--> 171\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# Use chunked scaling for memory efficiency\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         x \u001b[38;5;241m=\u001b[39m MemoryEfficientScaling\u001b[38;5;241m.\u001b[39mapply_scaling_chunked(\n\u001b[0;32m    176\u001b[0m             x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_chunk_size\n\u001b[0;32m    177\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday_era5\\src\\GriddedClimateDataset.py:62\u001b[0m, in \u001b[0;36mGriddedClimateDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables:\n\u001b[0;32m     61\u001b[0m     da \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[var]\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(t0, t1))  \u001b[38;5;66;03m# [T, H, W]\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m  \u001b[38;5;66;03m# triggers lazy load\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     x_vars\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m     65\u001b[0m x_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(x_vars, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape: [C, T, H, W]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\dataarray.py:809\u001b[0m, in \u001b[0;36mDataArray.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;124;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\variable.py:543\u001b[0m, in \u001b[0;36mVariable.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\variable.py:341\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[0;32m    328\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\array\\core.py:1696\u001b[0m, in \u001b[0;36mArray.__array__\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m   1698\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\base.py:372\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.LSTMGlobal.lstm_global import LSTMPyTorchGlobalPipeline\n",
    "pipeline = LSTMPyTorchGlobalPipeline(\"./config_lstmglobal.yaml\")\n",
    "pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade42c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought_lstm_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
