{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8d0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added project root to sys.path: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd42f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LEN = 12  # Number of input time steps\n",
    "FORECAST_LEN = 6  # Number of forecast time steps\n",
    "PATH = \"gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr\"\n",
    "VARIABLES = [\n",
    "    'total_precipitation_6hr',\n",
    "    '2m_temperature', '2m_dewpoint_temperature', 'surface_pressure',\n",
    "    'mean_sea_level_pressure', '10m_u_component_of_wind', '10m_v_component_of_wind',\n",
    "    '10m_wind_speed', 'u_component_of_wind', 'v_component_of_wind',\n",
    "    'total_column_water_vapour', 'integrated_vapor_transport', 'boundary_layer_height',\n",
    "    'specific_humidity', 'total_cloud_cover',\n",
    "    'mean_surface_net_short_wave_radiation_flux',\n",
    "    'mean_surface_latent_heat_flux', 'mean_surface_sensible_heat_flux',\n",
    "    'snow_depth', 'sea_surface_temperature', 'volumetric_soil_water_layer_1',\n",
    "    'mean_vertically_integrated_moisture_divergence', 'eddy_kinetic_energy',\n",
    "    'land_sea_mask'\n",
    "]\n",
    "TARGET_VARIABLE = 'total_precipitation_6hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cb83f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGriddedClimateDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GriddedClimateDataset\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGriddedClimateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINPUT_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORECAST_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVARIABLES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_VARIABLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1959\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday_era5\\src\\GriddedClimateDataset.py:18\u001b[0m, in \u001b[0;36mGriddedClimateDataset.__init__\u001b[1;34m(self, file_path, input_len, forecast_len, variables, target_variable, lat_bounds, lon_bounds, time_slice)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(file_path)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masynchronous\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcftime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m num2date\n\u001b[0;32m     21\u001b[0m     units \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhours since 1900-01-01 00:00:0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\backends\\zarr.py:1103\u001b[0m, in \u001b[0;36mopen_zarr\u001b[1;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_zarr() got unexpected keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m   1091\u001b[0m     )\n\u001b[0;32m   1093\u001b[0m backend_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynchronizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: synchronizer,\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsolidated\u001b[39m\u001b[38;5;124m\"\u001b[39m: consolidated,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: zarr_version,\n\u001b[0;32m   1101\u001b[0m }\n\u001b[1;32m-> 1103\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\backends\\api.py:617\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    611\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[0;32m    612\u001b[0m     filename_or_obj,\n\u001b[0;32m    613\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    616\u001b[0m )\n\u001b[1;32m--> 617\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43m_dataset_from_backend_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\backends\\api.py:393\u001b[0m, in \u001b[0;36m_dataset_from_backend_dataset\u001b[1;34m(backend_ds, filename_or_obj, engine, chunks, cache, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs, **extra_tokens)\u001b[0m\n\u001b[0;32m    391\u001b[0m     ds \u001b[38;5;241m=\u001b[39m backend_ds\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 393\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43m_chunk_ds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m ds\u001b[38;5;241m.\u001b[39mset_close(backend_ds\u001b[38;5;241m.\u001b[39m_close)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Ensure source filename always stored in dataset object\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\backends\\api.py:358\u001b[0m, in \u001b[0;36m_chunk_ds\u001b[1;34m(backend_ds, filename_or_obj, engine, chunks, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs, **extra_tokens)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, var \u001b[38;5;129;01min\u001b[39;00m backend_ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    357\u001b[0m     var_chunks \u001b[38;5;241m=\u001b[39m _get_chunk(var, chunks, chunkmanager)\n\u001b[1;32m--> 358\u001b[0m     variables[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43minline_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunkmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend_ds\u001b[38;5;241m.\u001b[39m_replace(variables)\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\dataset.py:329\u001b[0m, in \u001b[0;36m_maybe_chunk\u001b[1;34m(name, var, chunks, token, lock, name_prefix, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     name2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mconsolidate_dask_from_array_kwargs(\n\u001b[0;32m    323\u001b[0m         from_array_kwargs,\n\u001b[0;32m    324\u001b[0m         name\u001b[38;5;241m=\u001b[39mname2,\n\u001b[0;32m    325\u001b[0m         lock\u001b[38;5;241m=\u001b[39mlock,\n\u001b[0;32m    326\u001b[0m         inline_array\u001b[38;5;241m=\u001b[39minline_array,\n\u001b[0;32m    327\u001b[0m     )\n\u001b[1;32m--> 329\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overwrite_encoded_chunks \u001b[38;5;129;01mand\u001b[39;00m var\u001b[38;5;241m.\u001b[39mchunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     var\u001b[38;5;241m.\u001b[39mencoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m var\u001b[38;5;241m.\u001b[39mchunks)\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\variable.py:2604\u001b[0m, in \u001b[0;36mVariable.chunk\u001b[1;34m(self, chunks, name, lock, inline_array, chunked_array_type, from_array_kwargs, **chunks_kwargs)\u001b[0m\n\u001b[0;32m   2596\u001b[0m \u001b[38;5;66;03m# TODO deprecate passing these dask-specific arguments explicitly. In future just pass everything via from_array_kwargs\u001b[39;00m\n\u001b[0;32m   2597\u001b[0m _from_array_kwargs \u001b[38;5;241m=\u001b[39m consolidate_dask_from_array_kwargs(\n\u001b[0;32m   2598\u001b[0m     from_array_kwargs,\n\u001b[0;32m   2599\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2600\u001b[0m     lock\u001b[38;5;241m=\u001b[39mlock,\n\u001b[0;32m   2601\u001b[0m     inline_array\u001b[38;5;241m=\u001b[39minline_array,\n\u001b[0;32m   2602\u001b[0m )\n\u001b[1;32m-> 2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_from_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchunks_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\namedarray\\core.py:844\u001b[0m, in \u001b[0;36mNamedArray.chunk\u001b[1;34m(self, chunks, chunked_array_type, from_array_kwargs, **chunks_kwargs)\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(chunks):\n\u001b[0;32m    842\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(chunks\u001b[38;5;241m.\u001b[39mget(n, s) \u001b[38;5;28;01mfor\u001b[39;00m n, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ndata\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m--> 844\u001b[0m     data_chunked \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace(data\u001b[38;5;241m=\u001b[39mdata_chunked)\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\namedarray\\daskmanager.py:75\u001b[0m, in \u001b[0;36mDaskManager.from_array\u001b[1;34m(self, data, chunks, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ImplicitToExplicitIndexingAdapter):\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# lazily loaded backend array classes should use NumPy array operations.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\array\\core.py:3562\u001b[0m, in \u001b[0;36mfrom_array\u001b[1;34m(x, chunks, name, lock, asarray, fancy, getitem, meta, inline_array)\u001b[0m\n\u001b[0;32m   3559\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3560\u001b[0m             getitem \u001b[38;5;241m=\u001b[39m getter_nofancy\n\u001b[1;32m-> 3562\u001b[0m     dsk \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_from_arraylike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgetitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetitem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43masarray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43minline_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3574\u001b[0m \u001b[38;5;66;03m# Workaround for TileDB, its indexing is 1-based,\u001b[39;00m\n\u001b[0;32m   3575\u001b[0m \u001b[38;5;66;03m# and doesn't seems to support 0-length slicing\u001b[39;00m\n\u001b[0;32m   3576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiledb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ctx_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\array\\core.py:307\u001b[0m, in \u001b[0;36mgraph_from_arraylike\u001b[1;34m(arr, chunks, shape, name, getitem, lock, asarray, dtype, inline_array)\u001b[0m\n\u001b[0;32m    305\u001b[0m layers \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    306\u001b[0m layers[original_name] \u001b[38;5;241m=\u001b[39m MaterializedLayer({original_name: arr})\n\u001b[1;32m--> 307\u001b[0m layers[name] \u001b[38;5;241m=\u001b[39m \u001b[43mcore_blockwise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetitem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mArraySliceDep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumblocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m deps \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    320\u001b[0m     original_name: \u001b[38;5;28mset\u001b[39m(),\n\u001b[0;32m    321\u001b[0m     name: {original_name},\n\u001b[0;32m    322\u001b[0m }\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HighLevelGraph(layers, deps)\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\blockwise.py:313\u001b[0m, in \u001b[0;36mblockwise\u001b[1;34m(func, output, output_indices, numblocks, concatenate, new_axes, dependencies, *arrind_pairs, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     subgraph \u001b[38;5;241m=\u001b[39m {output: (apply, func, _keys, kwargs2)}\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# Construct final output\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m subgraph \u001b[38;5;241m=\u001b[39m \u001b[43mBlockwise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumblocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumblocks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subgraph\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\blockwise.py:418\u001b[0m, in \u001b[0;36mBlockwise.__init__\u001b[1;34m(self, output, output_indices, dsk, indices, numblocks, concatenate, new_axes, output_blocks, annotations, io_deps)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dep, ind \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dep, BlockwiseDep):\n\u001b[1;32m--> 418\u001b[0m         name \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m         io_deps[name] \u001b[38;5;241m=\u001b[39m dep\n\u001b[0;32m    420\u001b[0m         numblocks[name] \u001b[38;5;241m=\u001b[39m dep\u001b[38;5;241m.\u001b[39mnumblocks\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\tokenize.py:71\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(ensure_deterministic, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m _ENSURE_DETERMINISTIC \u001b[38;5;241m=\u001b[39m ensure_deterministic\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     _SEEN \u001b[38;5;241m=\u001b[39m seen_before\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\tokenize.py:33\u001b[0m, in \u001b[0;36m_tokenize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tokenize\u001b[39m(\u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mobject\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 33\u001b[0m     token: \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_seq_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m     35\u001b[0m         token \u001b[38;5;241m=\u001b[39m token, _normalize_seq_func(\u001b[38;5;28msorted\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\tokenize.py:146\u001b[0m, in \u001b[0;36m_normalize_seq_func\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    144\u001b[0m _SEEN[\u001b[38;5;28mid\u001b[39m(seq)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_SEEN), seq\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_inner_normalize_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _SEEN[\u001b[38;5;28mid\u001b[39m(seq)]\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\tokenize.py:140\u001b[0m, in \u001b[0;36m_normalize_seq_func.<locals>._inner_normalize_token\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _IDENTITY_DISPATCH):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\utils.py:773\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    772\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;28mtype\u001b[39m(arg))\n\u001b[1;32m--> 773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\tokenize.py:202\u001b[0m, in \u001b[0;36mnormalize_object\u001b[1;34m(o)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _normalize_dataclass(o)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_normalize_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     _maybe_raise_nondeterministic(\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m cannot be deterministically hashed. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.dask.org/en/latest/custom-collections.html#implementing-deterministic-hashing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\tokenize.py:237\u001b[0m, in \u001b[0;36m_normalize_pickle\u001b[1;34m(o)\u001b[0m\n\u001b[0;32m    235\u001b[0m     out \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mdumps(o, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, buffer_callback\u001b[38;5;241m=\u001b[39mbuffers\u001b[38;5;241m.\u001b[39mappend)\n\u001b[0;32m    236\u001b[0m     mod\u001b[38;5;241m.\u001b[39mloads(out, buffers\u001b[38;5;241m=\u001b[39mbuffers)\n\u001b[1;32m--> 237\u001b[0m     pik2 \u001b[38;5;241m=\u001b[39m \u001b[43mhash_buffer_hex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\hashing.py:98\u001b[0m, in \u001b[0;36mhash_buffer_hex\u001b[1;34m(buf, hasher)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash_buffer_hex\u001b[39m(buf, hasher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Same as hash_buffer, but returns its result in hex-encoded form.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mhash_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     s \u001b[38;5;241m=\u001b[39m binascii\u001b[38;5;241m.\u001b[39mb2a_hex(h)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mdecode()\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\hashing.py:88\u001b[0m, in \u001b[0;36mhash_buffer\u001b[1;34m(buf, hasher)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hasher \u001b[38;5;129;01min\u001b[39;00m hashers:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhasher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mOverflowError\u001b[39;00m):\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\hashing.py:67\u001b[0m, in \u001b[0;36m_hash_sha1\u001b[1;34m(buf)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_hash_sha1\u001b[39m(buf):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Produce a 20-bytes hash of *buf* using SHA1.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhashlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msha1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdigest()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.GriddedClimateDataset import GriddedClimateDataset\n",
    "dataset = GriddedClimateDataset(PATH, input_len=INPUT_LEN, forecast_len=FORECAST_LEN, \n",
    "                                  variables=VARIABLES, target_variable=TARGET_VARIABLE,time_slice=slice(\"1959\", \"2023\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d336595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d49277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating min/max for scaling:   0%|          | 0/24 [03:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(da\u001b[38;5;241m.\u001b[39mdims) \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m     12\u001b[0m         da \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mexpand_dims(time\u001b[38;5;241m=\u001b[39mds\u001b[38;5;241m.\u001b[39mtime)  \u001b[38;5;66;03m# Broadcast static vars\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     mins\u001b[38;5;241m.\u001b[39mappend(\u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m     maxs\u001b[38;5;241m.\u001b[39mappend(da\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mcompute())\n\u001b[0;32m     16\u001b[0m x_data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mfloat\u001b[39m(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m mins])\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\dataarray.py:1202\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\dataarray.py:1170\u001b[0m, in \u001b[0;36mDataArray.load\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1170\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\core\\dataset.py:870\u001b[0m, in \u001b[0;36mDataset.load\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    869\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\xarray\\namedarray\\daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[1;34m(self, *data, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\dask\\base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "input_vars = VARIABLES # ← your config['variables']\n",
    "mins, maxs = [], []\n",
    "from tqdm import tqdm\n",
    "for var in tqdm(input_vars, desc=\"Calculating min/max for scaling\"):\n",
    "    da = ds[var]\n",
    "    if \"level\" in da.dims:\n",
    "        da = da.mean(dim=\"level\")  # Collapse level\n",
    "    if set(da.dims) == {\"latitude\", \"longitude\"}:\n",
    "        da = da.expand_dims(time=ds.time)  # Broadcast static vars\n",
    "    mins.append(da.min().compute())\n",
    "    maxs.append(da.max().compute())\n",
    "\n",
    "x_data_min = np.array([float(m) for m in mins])\n",
    "x_data_max = np.array([float(m) for m in maxs])\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_x.min_ = -x_data_min * (2.0 / (x_data_max - x_data_min + 1e-8))\n",
    "scaler_x.scale_ = 2.0 / (x_data_max - x_data_min + 1e-8)\n",
    "scaler_x.data_min_ = x_data_min\n",
    "scaler_x.data_max_ = x_data_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b98fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = TARGET_VARIABLE  # or your config['target_variable']\n",
    "target = ds[target_var]\n",
    "if \"level\" in target.dims:\n",
    "    target = target.mean(dim=\"level\")\n",
    "target_min = float(target.min().compute())\n",
    "target_max = float(target.max().compute())\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_y.min_ = -target_min * (2.0 / (target_max - target_min + 1e-8))\n",
    "scaler_y.scale_ = 2.0 / (target_max - target_min + 1e-8)\n",
    "scaler_y.data_min_ = np.array([target_min])\n",
    "scaler_y.data_max_ = np.array([target_max])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought_lstm_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
