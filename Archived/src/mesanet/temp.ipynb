{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 7. MAIN EXECUTION AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_mesa_net_config():\n",
    "    \"\"\"Create default configuration for MESA-Net\"\"\"\n",
    "    return {\n",
    "        'model': {\n",
    "            'input_channels': 15,  # Number of meteorological variables (adjusted)\n",
    "            'num_layers': 3,\n",
    "            'hidden_dim': 128,\n",
    "            'memory_config': MemoryConfig(\n",
    "                num_states=3,\n",
    "                hidden_dim=128,\n",
    "                learning_rates={\n",
    "                    'alert': 0.1,\n",
    "                    'normal': 0.01,\n",
    "                    'suppressed': 0.001\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        'training': {\n",
    "            'batch_size': 16,  # Reduced for memory efficiency\n",
    "            'learning_rate': 1e-4,\n",
    "            'num_epochs': 100,\n",
    "            'sequence_length': 12,  # 3 days of 6h data\n",
    "            'forecast_horizon': 4,  # 1 day ahead\n",
    "            'num_workers': 2,  # For data loading\n",
    "        },\n",
    "        'data': {\n",
    "            'zarr_path': \"gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr\",\n",
    "            'variables': [\n",
    "                'total_precipitation_6hr',\n",
    "                '2m_temperature', '2m_dewpoint_temperature',\n",
    "                'surface_pressure', 'mean_sea_level_pressure',\n",
    "                '10m_u_component_of_wind', '10m_v_component_of_wind',\n",
    "                'u_component_of_wind', 'v_component_of_wind',\n",
    "                'specific_humidity', 'relative_humidity',\n",
    "                'total_column_water_vapour', 'total_cloud_cover',\n",
    "                'vertical_velocity', 'geopotential_at_surface'\n",
    "            ],\n",
    "            'time_range': slice(\"2015\", \"2023\"),  # Recent years for faster development\n",
    "            'normalize': True\n",
    "        },\n",
    "        'loss': {\n",
    "            'alpha_prediction': 1.0,\n",
    "            'alpha_state_entropy': 0.1,\n",
    "            'alpha_transition_smooth': 0.01,\n",
    "            'alpha_cross_memory': 0.05,\n",
    "            'alpha_cross_layer': 0.05\n",
    "        }\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate MESA-Net usage\"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    config = create_mesa_net_config()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 1. Initialize data manager and create datasets\n",
    "    print(\"Initializing datasets...\")\n",
    "    data_manager = WeatherBench2DataManager(\n",
    "        zarr_path=config['data']['zarr_path'],\n",
    "        variables=config['data']['variables'],\n",
    "        sequence_length=config['training']['sequence_length'],\n",
    "        forecast_horizon=config['training']['forecast_horizon']\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset, val_dataset, test_dataset = data_manager.create_datasets(\n",
    "        time_range=config['data']['time_range'],\n",
    "        normalize=config['data']['normalize']\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = data_manager.create_data_loaders(\n",
    "        datasets=(train_dataset, val_dataset, test_dataset),\n",
    "        batch_size=config['training']['batch_size'],\n",
    "        num_workers=config['training']['num_workers']\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # 2. Initialize model\n",
    "    print(\"Initializing MESA-Net model...\")\n",
    "    model = MESANet(\n",
    "        input_channels=config['model']['input_channels'],\n",
    "        num_layers=config['model']['num_layers'],\n",
    "        hidden_dim=config['model']['hidden_dim'],\n",
    "        memory_config=config['model']['memory_config']\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # 3. Initialize loss function and optimizer\n",
    "    loss_fn = MESANetLoss(\n",
    "        alpha_prediction=config['loss']['alpha_prediction'],\n",
    "        alpha_state_entropy=config['loss']['alpha_state_entropy'],\n",
    "        alpha_transition_smooth=config['loss']['alpha_transition_smooth'],\n",
    "        alpha_cross_memory=config['loss']['alpha_cross_memory'],\n",
    "        alpha_cross_layer=config['loss']['alpha_cross_layer']\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config['training']['learning_rate'],\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    \n",
    "    # 4. Initialize trainer\n",
    "    trainer = MESANetTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        save_dir=\"./mesa_net_checkpoints\"\n",
    "    )\n",
    "    \n",
    "    # 5. Training\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train(num_epochs=config['training']['num_epochs'])\n",
    "    \n",
    "    # 6. Evaluation\n",
    "    print(\"Starting evaluation...\")\n",
    "    evaluator = MESANetEvaluator(model, device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"Evaluating on test set...\")\n",
    "    metrics = evaluator._evaluate_model(model, test_loader)\n",
    "    print(\"Final metrics:\", metrics)\n",
    "    \n",
    "    print(\"MESA-Net training and evaluation completed!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. QUICK TEST FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def test_data_loading():\n",
    "    \"\"\"Quick test function to verify data loading works\"\"\"\n",
    "    print(\"Testing data loading...\")\n",
    "    \n",
    "    config = create_mesa_net_config()\n",
    "    \n",
    "    # Create a small test dataset\n",
    "    try:\n",
    "        data_manager = WeatherBench2DataManager(\n",
    "            zarr_path=config['data']['zarr_path'],\n",
    "            variables=config['data']['variables'][:5],  # Test with fewer variables\n",
    "            sequence_length=4,  # Shorter sequences for testing\n",
    "            forecast_horizon=2\n",
    "        )\n",
    "        \n",
    "        train_dataset, val_dataset, test_dataset = data_manager.create_datasets(\n",
    "            time_range=slice(\"2023\", \"2023\"),  # Just 2023 for testing\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Test getting a single sample\n",
    "        sample_input, sample_target, sample_geo = train_dataset[0]\n",
    "        \n",
    "        print(f\"✓ Data loading successful!\")\n",
    "        print(f\"  Input shape: {sample_input.shape}\")\n",
    "        print(f\"  Target shape: {sample_target.shape}\")\n",
    "        print(f\"  Geo features shape: {sample_geo.shape}\")\n",
    "        print(f\"  Train dataset size: {len(train_dataset)}\")\n",
    "        \n",
    "        # Test data loader\n",
    "        train_loader, val_loader, test_loader = data_manager.create_data_loaders(\n",
    "            datasets=(train_dataset, val_dataset, test_dataset),\n",
    "            batch_size=2,\n",
    "            num_workers=0  # No multiprocessing for testing\n",
    "        )\n",
    "        \n",
    "        # Get one batch\n",
    "        for batch_input, batch_target, batch_geo in train_loader:\n",
    "            print(f\"✓ Batch loading successful!\")\n",
    "            print(f\"  Batch input shape: {batch_input.shape}\")\n",
    "            print(f\"  Batch target shape: {batch_target.shape}\")\n",
    "            print(f\"  Batch geo shape: {batch_geo.shape}\")\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Data loading failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Uncomment for quick data loading test\n",
    "    # test_data_loading()\n",
    "    \n",
    "    # Uncomment for full training\n",
    "    main()\n",
    "\n",
    "# =============================================================================\n",
    "# 9. IMPLEMENTATION PHASES BREAKDOWN\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "PHASE 1: Foundation (Month 1) - UPDATED\n",
    "├── ✓ WeatherBench2Dataset - Proper PyTorch Dataset class\n",
    "├── ✓ WeatherBench2DataManager - Dataset and DataLoader creation\n",
    "├── ✓ Basic memory components - Individual memory types\n",
    "├── ✓ PredRNN++ baseline - Cross-layer memory flow\n",
    "└── ✓ Fixed state testing - Verify architecture works\n",
    "\n",
    "Next Steps for Phase 1:\n",
    "1. Run test_data_loading() to verify data pipeline\n",
    "2. Test basic MESANetLayer with fixed states\n",
    "3. Create simple training script for baseline\n",
    "4. Verify gradient flow and memory usage\n",
    "5. Monitor GPU memory consumption\n",
    "\n",
    "PHASE 2: State Machines (Month 2-3)\n",
    "├── ✓ StateTransitionNetwork - Attention-based transitions\n",
    "├── ✓ MemoryStateMachine - State-dependent processing\n",
    "├── ✓ Cross-memory interactions - Memory coordination\n",
    "└── ☐ Dynamic state learning - Train state transitions\n",
    "\n",
    "Next Steps for Phase 2:\n",
    "1. Implement state transition training\n",
    "2. Add state regularization\n",
    "3. Test different attention mechanisms\n",
    "4. Analyze learned state patterns\n",
    "5. Validate state interpretability\n",
    "\n",
    "PHASE 3: Full Integration (Month 3-4)\n",
    "├── ✓ Complete MESA architecture - All components together\n",
    "├── ✓ Training pipeline - Full training loop with DataLoader\n",
    "├── ✓ Evaluation framework - Comprehensive metrics\n",
    "└── ✓ Interpretability tools - State analysis\n",
    "\n",
    "Next Steps for Phase 3:\n",
    "1. Run full training pipeline\n",
    "2. Test end-to-end training\n",
    "3. Implement ablation studies\n",
    "4. Add visualization tools\n",
    "5. Performance optimization\n",
    "\n",
    "PHASE 4: Optimization (Month 4-5)\n",
    "├── ☐ Hyperparameter tuning - Grid search/Bayesian opt\n",
    "├── ☐ Performance analysis - Speed and accuracy\n",
    "├── ☐ Ablation studies - Component importance\n",
    "└── ☐ Publication preparation - Results and writing\n",
    "\n",
    "Key Implementation Improvements:\n",
    "1. ✓ Proper PyTorch Dataset class with normalization\n",
    "2. ✓ Automatic train/val/test splitting\n",
    "3. ✓ Built-in data loading efficiency\n",
    "4. ✓ Memory-efficient streaming from cloud\n",
    "5. ✓ Geographic features handling\n",
    "6. ✓ Error handling and data validation\n",
    "\n",
    "Usage:\n",
    "1. Start with test_data_loading() to verify setup\n",
    "2. Run main() for full training pipeline\n",
    "3. Monitor GPU memory and adjust batch_size if needed\n",
    "4. Use saved checkpoints for evaluation and analysis\n",
    "\"\"\"\n",
    "\n",
    "class MESANetEvaluator:\n",
    "    \"\"\"Evaluation and interpretation tools for MESA-Net\"\"\"\n",
    "    \n",
    "    def __init__(self, model: MESANet, device: torch.device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        \n",
    "    def evaluate_precipitation_metrics(self, \n",
    "                                     predictions: torch.Tensor,\n",
    "                                     targets: torch.Tensor) -> Dict[str, float]:\n",
    "        \"\"\"Compute precipitation-specific evaluation metrics\"\"\"\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        \n",
    "        # Basic metrics\n",
    "        mse = np.mean((predictions - targets) ** 2)\n",
    "        mae = np.mean(np.abs(predictions - targets))\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Precipitation-specific metrics\n",
    "        # Critical Success Index (CSI) for precipitation detection\n",
    "        threshold = 0.1  # mm/6hr precipitation threshold\n",
    "        pred_binary = (predictions > threshold).astype(int)\n",
    "        target_binary = (targets > threshold).astype(int)\n",
    "        \n",
    "        hits = np.sum((pred_binary == 1) & (target_binary == 1))\n",
    "        misses = np.sum((pred_binary == 0) & (target_binary == 1))\n",
    "        false_alarms = np.sum((pred_binary == 1) & (target_binary == 0))\n",
    "        \n",
    "        csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0\n",
    "        \n",
    "        # Probability of Detection (POD)\n",
    "        pod = hits / (hits + misses) if (hits + misses) > 0 else 0\n",
    "        \n",
    "        # False Alarm Rate (FAR)\n",
    "        far = false_alarms / (hits + false_alarms) if (hits + false_alarms) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'csi': csi,\n",
    "            'pod': pod,\n",
    "            'far': far\n",
    "        }\n",
    "    \n",
    "    def analyze_state_patterns(self, states_history: Dict) -> Dict[str, any]:\n",
    "        \"\"\"Analyze learned state patterns for interpretability\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        # Extract state probabilities over time\n",
    "        memory_types = ['fast', 'slow', 'spatial', 'spatiotemporal']\n",
    "        \n",
    "        for memory_type in memory_types:\n",
    "            state_evolution = []\n",
    "            for timestep in states_history['state_probs']:\n",
    "                state_probs = timestep[memory_type]\n",
    "                # Average over batch dimension\n",
    "                avg_probs = torch.mean(state_probs, dim=0).cpu().numpy()\n",
    "                state_evolution.append(avg_probs)\n",
    "            \n",
    "            state_evolution = np.array(state_evolution)  # Shape: (time, num_states)\n",
    "            \n",
    "            analysis[f'{memory_type}_state_evolution'] = state_evolution\n",
    "            analysis[f'{memory_type}_dominant_state'] = np.argmax(state_evolution, axis=1)\n",
    "            analysis[f'{memory_type}_state_stability'] = np.std(state_evolution, axis=0)\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_attention_maps(self, \n",
    "                               input_sequence: torch.Tensor,\n",
    "                               geo_features: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Generate attention maps for visualization\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Forward pass with hooks to capture intermediate attention\n",
    "            predictions, states_history = self.model(input_sequence, geo_features)\n",
    "            \n",
    "            # Extract attention patterns from the last layer\n",
    "            attention_maps = {}\n",
    "            \n",
    "            # This would require modifying the model to return attention weights\n",
    "            # For now, return placeholder\n",
    "            batch_size, seq_len, height, width = input_sequence.shape[:2] + input_sequence.shape[-2:]\n",
    "            \n",
    "            attention_maps['spatial_attention'] = torch.randn(batch_size, height, width)\n",
    "            attention_maps['temporal_attention'] = torch.randn(batch_size, seq_len)\n",
    "            \n",
    "        return attention_maps\n",
    "    \n",
    "    def compare_with_baselines(self, \n",
    "                              test_data_loader: WeatherBench2DataLoader,\n",
    "                              baseline_models: Dict[str, nn.Module]) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Compare MESA-Net with baseline models\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Evaluate MESA-Net\n",
    "        mesa_metrics = self._evaluate_model(self.model, test_data_loader)\n",
    "        results['MESA-Net'] = mesa_metrics\n",
    "        \n",
    "        # Evaluate baseline models\n",
    "        for model_name, model in baseline_models.items():\n",
    "            baseline_metrics = self._evaluate_model(model, test_data_loader)\n",
    "            results[model_name] = baseline_metrics\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model: nn.Module, data_loader: WeatherBench2DataLoader) -> Dict[str, float]:\n",
    "        \"\"\"Helper function to evaluate any model\"\"\"\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx in range(min(50, len(data_loader) // data_loader.batch_size)):\n",
    "                start_idx = batch_idx * data_loader.batch_size\n",
    "                end_idx = start_idx + data_loader.batch_size\n",
    "                batch_indices = data_loader.time_indices[start_idx:end_idx]\n",
    "                \n",
    "                input_seq, target_seq = data_loader.get_sequence_batch(batch_indices)\n",
    "                input_seq = input_seq.to(self.device)\n",
    "                target_seq = target_seq.to(self.device)\n",
    "                \n",
    "                if hasattr(model, 'forward') and 'geo_features' in model.forward.__code__.co_varnames:\n",
    "                    # MESA-Net style model\n",
    "                    batch_size, seq_len, channels, height, width = input_seq.shape\n",
    "                    geo_features = torch.zeros(batch_size, 4, height, width, device=self.device)\n",
    "                    predictions, _ = model(input_seq, geo_features)\n",
    "                else:\n",
    "                    # Standard model\n",
    "                    predictions = model(input_seq)\n",
    "                \n",
    "                all_predictions.append(predictions.cpu())\n",
    "                all_targets.append(target_seq.cpu())\n",
    "        \n",
    "        all_predictions = torch.cat(all_predictions, dim=0)\n",
    "        all_targets = torch.cat(all_targets, dim=0)\n",
    "        \n",
    "        return self.evaluate_precipitation_metrics(all_predictions, all_targets)\n",
    "\n",
    "# =============================================================================\n",
    "# 7. MAIN EXECUTION AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. IMPLEMENTATION PHASES BREAKDOWN\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "PHASE 1: Foundation (Month 1)\n",
    "├── ✓ WeatherBench2DataLoader - Stream data from cloud\n",
    "├── ✓ Basic memory components - Individual memory types\n",
    "├── ✓ PredRNN++ baseline - Cross-layer memory flow\n",
    "└── ✓ Fixed state testing - Verify architecture works\n",
    "\n",
    "Next Steps for Phase 1:\n",
    "1. Test WeatherBench2DataLoader with actual data\n",
    "2. Implement _to_tensor() method in data loader\n",
    "3. Test basic MESANetLayer with fixed states\n",
    "4. Create simple training script for baseline\n",
    "5. Verify gradient flow and memory usage\n",
    "\n",
    "PHASE 2: State Machines (Month 2-3)\n",
    "├── ✓ StateTransitionNetwork - Attention-based transitions\n",
    "├── ✓ MemoryStateMachine - State-dependent processing\n",
    "├── ✓ Cross-memory interactions - Memory coordination\n",
    "└── ☐ Dynamic state learning - Train state transitions\n",
    "\n",
    "Next Steps for Phase 2:\n",
    "1. Implement state transition training\n",
    "2. Add state regularization\n",
    "3. Test different attention mechanisms\n",
    "4. Analyze learned state patterns\n",
    "5. Validate state interpretability\n",
    "\n",
    "PHASE 3: Full Integration (Month 3-4)\n",
    "├── ✓ Complete MESA architecture - All components together\n",
    "├── ✓ Training pipeline - Full training loop\n",
    "├── ✓ Evaluation framework - Comprehensive metrics\n",
    "└── ☐ Interpretability tools - State analysis\n",
    "\n",
    "Next Steps for Phase 3:\n",
    "1. Integrate all components\n",
    "2. Test end-to-end training\n",
    "3. Implement ablation studies\n",
    "4. Add visualization tools\n",
    "5. Performance optimization\n",
    "\n",
    "PHASE 4: Optimization (Month 4-5)\n",
    "├── ☐ Hyperparameter tuning - Grid search/Bayesian opt\n",
    "├── ☐ Performance analysis - Speed and accuracy\n",
    "├── ☐ Ablation studies - Component importance\n",
    "└── ☐ Publication preparation - Results and writing\n",
    "\n",
    "Key Implementation Priorities:\n",
    "1. Get basic data loading working first\n",
    "2. Test individual components before integration\n",
    "3. Start with simple fixed states\n",
    "4. Add complexity gradually\n",
    "5. Monitor memory usage and training stability\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
