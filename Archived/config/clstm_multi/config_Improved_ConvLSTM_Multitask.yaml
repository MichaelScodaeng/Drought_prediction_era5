# === MULTITASK CONFIG (New multitask functionality) ===
# config_multitask_pre_pet.yaml
# === ADVANCED MULTITASK CONFIG ===
# config_advanced_multitask.yaml
project_setup:
  experiment_name: "Advanced_PRE_PET_Multitask"
  target_variable: ["pre", "pet"]
  random_seed: 42

data:
  raw_data_path:  "data/processed/full_scaled.csv"
  scaler_path_pre: "data/processed/robust_scaler_pre.joblib"
  scaler_path_pet: "data/processed/robust_scaler_pet.joblib"
  time_column: "time"
  lat_column: "lat"
  lon_column: "lon"
  features_to_grid: [
      'tmp', 'dtr', 'cld', 'tmx', 
      'tmn', 'wet', 'vap', 'soi', 
      'dmi', 'pdo', 'nino4', 
      'nino34', 'nino3', 'pre', 'pet'
    ]
  train_end_date: "2017-12-31"
  validation_end_date: "2020-12-31"

gridding:
  fixed_step: 0.5 

sequence_params:
  n_steps_in: 12      
  n_steps_out: 1  # Predict 3 time steps ahead

convlstm_params:
  batch_size: 8
  
  trainer:
    max_epochs: 1000 # Increased epochs for multitask training
    patience_for_early_stopping: 30
    enable_progress_bar: True
    gradient_clip_val: 1.0
    precision: 32
  
  tuning:
    max_epochs: 50 # Reduced epochs for hyperparameter tuning
    n_trials: 200  # More trials for multitask optimization
    learning_rate: {low: 1.0e-4, high: 1.0e-3, log: True}
    hidden_dim_size: {choices: [64,128,256]}
    n_layers: {low: 1, high: 3}
    kernel_size: {choices: [3, 5, 7]}
    dropout: {low: 0.1, high: 0.4}
    weight_decay: {low: 1.0e-6, high: 1.0e-3, log: True}
    batch_norm: [true, false]
    teacher_forcing_ratio: {low: 0.3, high: 0.8}
    
    # Multitask hyperparameters
    multitask_fusion: {choices: ["shared"]}
    weight_pre: {low: 0.3, high: 3.0}
    weight_pet: {low: 0.3, high: 3.0}


results:
  output_base_dir: "run_outputs" 
  metrics_filename: "advanced_multitask_metrics.json"
  predictions_filename: "advanced_multitask_predictions.csv"
  save_task_specific_metrics: true
  save_cross_correlation_analysis: true